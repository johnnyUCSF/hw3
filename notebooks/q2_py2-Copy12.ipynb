{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from hw3 import io\n",
    "from hw3 import smith_waterman\n",
    "from hw3 import optimize\n",
    "from hw3 import visualize\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def byFirst(elem):\n",
    "    return elem[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question 2\n",
    "\n",
    "#### 2.1. I implemented particle swarm optimization in \"optimize.py\"\n",
    "#### 2.2. Below: Optimization of BLOSUM50 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####import blosum matrix\n",
    "blosums = []\n",
    "blosum_files = ['BLOSUM50']\n",
    "for file in blosum_files:\n",
    "    importme = 'blosums/'+file\n",
    "    blosums.append(io.import_blosum(importme))\n",
    "###################\n",
    "scoring_matrix = blosums[0]\n",
    "FPRs = [0.0,0.1,0.2,0.3]\n",
    "pen_gap_extend = -5\n",
    "pen_gap_open = -6\n",
    "true_pos = io.import_pairs('data/Pospairs.txt')\n",
    "true_neg = io.import_pairs('data/Negpairs.txt')\n",
    "###see what the fitness is prior to starting\n",
    "optimize.calc_fitness(FPRs,blosums[0],true_pos,true_neg,pen_gap_open,pen_gap_extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The fitness for PAM100 before optimization is: \n",
    "## 2.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#######\n",
    "particles = 50\n",
    "iterations = 10\n",
    "###################\n",
    "optimized_output = optimize.particle_swarm(scoring_matrix,FPRs,pen_gap_extend,pen_gap_open,true_pos,true_neg,particles,iterations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The fitness after optimization is:\n",
    "## 2.54\n",
    "\n",
    "### I will now compare the ROC curves of each matrix at true postive rate of 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "####readin\n",
    "true_pos = io.import_pairs('data/Pospairs.txt')\n",
    "true_neg = io.import_pairs('data/Negpairs.txt')\n",
    "all_pairs = [true_pos,true_neg]\n",
    "#####import blosum matrices\n",
    "blosums = []\n",
    "blosum_files = ['BLOSUM50']\n",
    "for file in blosum_files:\n",
    "    importme = 'blosums/'+file\n",
    "    blosums.append(io.import_blosum(importme))\n",
    "blosums.append(copy.deepcopy(optimized_output[1]))\n",
    "blosum_files.append('BLOSUM50 OPTIMIZED')\n",
    "#########calculate\n",
    "scores_array = []\n",
    "######\n",
    "for scoring_matrix in blosums:\n",
    "    score = []\n",
    "    for file in all_pairs:\n",
    "        for pair in file:\n",
    "            ###this contains just the scores\n",
    "            output = smith_waterman.smith_waterman(pair[0],pair[1],scoring_matrix,pen_gap_open,pen_gap_extend)\n",
    "            score.append([output[2],pair])\n",
    "    scores_array.append(score)\n",
    "#######\n",
    "threshold = 0.7\n",
    "all_FPRs = []\n",
    "#####\n",
    "for scores in scores_array:\n",
    "    FPR,TPR,AUC = visualize.calc_ROC(true_pos, true_neg, scores)\n",
    "    for tpr in TPR:\n",
    "        if tpr >= threshold:\n",
    "            all_FPRs.append(FPR[TPR.index(tpr)])\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ####initialize\n",
    "# total_confusions = []\n",
    "# pen_gap_extend = -5\n",
    "# pen_gap_open = -6\n",
    "# plt.figure(figsize=(10,10))\n",
    "# #####################\n",
    "# #####loop through scoring matrices and calculate confusion for each one\n",
    "# #####################\n",
    "# matrix_num = 0\n",
    "# line_widths = [5,2]\n",
    "# for scoring_matrix in blosums:\n",
    "#     total_scores = []\n",
    "#     ########do alignments for all pairs\n",
    "#     for file in all_pairs:\n",
    "#         for pair in file:\n",
    "#             ###this contains just the scores\n",
    "#             output = smith_waterman.smith_waterman(pair[0],pair[1],scoring_matrix,pen_gap_open,pen_gap_extend)\n",
    "#             total_scores.append([output[2],pair])\n",
    "#     #####determine true positives by TPR = 0.7\n",
    "#     ###sort, largest to smallest\n",
    "#     total_scores.sort(key=byFirst,reverse=True)\n",
    "#     ####loop through and count TPR until matches TPR = 0.7\n",
    "#     FPR = 0.3\n",
    "#     FP = 0\n",
    "#     TP = 0\n",
    "#     TPR = 0.0\n",
    "#     actual_FPR = -1\n",
    "#     predicted_pos = []\n",
    "#     predicted_neg = []\n",
    "#     found_all_positives = False\n",
    "#     for alignment in total_scores:\n",
    "#         tmp_rate = 0\n",
    "#         if found_all_positives == False:\n",
    "#             if alignment[1] not in true_pos: \n",
    "#                 #####evaluate new FPR\n",
    "#                 new_FPR = float(FP+1)/float(len(true_neg))\n",
    "#                 #####evaluate if this will exceed FPR threshold\n",
    "#                 ###this is used to handle small or 0 values of FPR\n",
    "#                 if new_FPR >= FPR:\n",
    "#                     found_all_positives = True\n",
    "#                     if FPR == 0:\n",
    "#                         predicted_neg.append(alignment)\n",
    "#                     else:\n",
    "#                         predicted_pos.append(alignment)\n",
    "#                 else:\n",
    "#                     FP += 1\n",
    "#                     actual_FPR = float(FP)/float(len(true_neg))\n",
    "#                     predicted_pos.append(alignment)\n",
    "#             else:\n",
    "#                 TP += 1\n",
    "#                 TPR = float(TP)/float(len(true_pos))\n",
    "#                 predicted_pos.append(alignment)\n",
    "#             if actual_FPR == FPR:\n",
    "#                 found_all_positives = True\n",
    "#         else:\n",
    "#             predicted_neg.append(alignment)   \n",
    "#     ####prepare for plotting ROC curves\n",
    "#     label = []\n",
    "#     pred = []\n",
    "#     ###by counting\n",
    "#     TP = 0\n",
    "#     FP = 0\n",
    "#     TN = 0\n",
    "#     FN = 0\n",
    "#     ###\n",
    "#     for alignment in total_scores:\n",
    "#         if alignment[1] in true_pos:\n",
    "#             label.append(1)\n",
    "#             TP += 1\n",
    "#         else:\n",
    "#             label.append(0)\n",
    "#             TN += 1\n",
    "#     ###\n",
    "#     for alignment in total_scores:\n",
    "#         if alignment in predicted_pos:\n",
    "#             pred.append(1)\n",
    "#         else:\n",
    "#             pred.append(0)\n",
    "#     ##\n",
    "#     FP = len(predicted_pos)-TP\n",
    "#     FN = len(predicted_neg)-TN\n",
    "#     #####plot\n",
    "#     fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "#     auc = metrics.roc_auc_score(label, pred)\n",
    "#     ###\n",
    "#     plt.plot(fpr,tpr,label=blosum_files[matrix_num]+\" auc=\"+str(auc),linewidth=line_widths[matrix_num%2],alpha=0.5)\n",
    "#     #####save confusion matrix\n",
    "#     confusion = [blosum_files[matrix_num],[TP,FP,TN,FN]]\n",
    "#     total_confusions.append(confusion)\n",
    "#     #####\n",
    "#     matrix_num +=1\n",
    "# ########\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.legend(loc=0)\n",
    "# plt.suptitle('Fig 6. ROC curve for PAM100 blosum matrix before and after matrix optimization.')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_ROCs(true_pos, true_neg, scores_array,blosum_files)\n",
    "print('Fig 3. ROC curves by BLOSUM matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Q2.3.\n",
    "#### Optimzation of MATIO scoring matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#####import blosum matrix\n",
    "blosums = []\n",
    "blosum_files = ['MATIO']\n",
    "for file in blosum_files:\n",
    "    importme = 'blosums/'+file\n",
    "    blosums.append(io.import_blosum(importme))\n",
    "###################\n",
    "scoring_matrix = blosums[0]\n",
    "FPRs = [0.0,0.1,0.2,0.3]\n",
    "pen_gap_extend = -5\n",
    "pen_gap_open = -6\n",
    "true_pos = io.import_pairs('data/Pospairs.txt')\n",
    "true_neg = io.import_pairs('data/Negpairs.txt')\n",
    "###see what the fitness is prior to starting\n",
    "calc_fitness(FPRs,blosums[0],true_pos,true_neg,pen_gap_open,pen_gap_extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The fitness for MATIO before optimization is: \n",
    "## 2.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "particles = 30\n",
    "iterations = 5\n",
    "###################\n",
    "optimized_output = optimize.particle_swarm(scoring_matrix,FPRs,pen_gap_extend,pen_gap_open,true_pos,true_neg,particles,iterations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The fitness after optimization is:\n",
    "## 2.40\n",
    "\n",
    "### I will now compare the ROC curves of each matrix at true postive rate of 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.3. Below: Optimization of MATIO 100 matrix (prior best)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "####readin\n",
    "true_pos = io.import_pairs('data/Pospairs.txt')\n",
    "true_neg = io.import_pairs('data/Negpairs.txt')\n",
    "all_pairs = [true_pos,true_neg]\n",
    "#####import blosum matrices\n",
    "blosums = []\n",
    "blosum_files = ['MATIO']\n",
    "for file in blosum_files:\n",
    "    importme = 'blosums/'+file\n",
    "    blosums.append(io.import_blosum(importme))\n",
    "blosums.append(copy.deepcopy(optimized_output[1]))\n",
    "blosum_files.append('MATIO OPTIMIZED')\n",
    "####initialize\n",
    "total_confusions = []\n",
    "pen_gap_extend = -5\n",
    "pen_gap_open = -6\n",
    "plt.figure(figsize=(10,10))\n",
    "#####################\n",
    "#####loop through scoring matrices and calculate confusion for each one\n",
    "#####################\n",
    "matrix_num = 0\n",
    "line_widths = [5,2]\n",
    "for scoring_matrix in blosums:\n",
    "    total_scores = []\n",
    "    ########do alignments for all pairs\n",
    "    for file in all_pairs:\n",
    "        for pair in file:\n",
    "            ###this contains just the scores\n",
    "            output = smith_waterman.smith_waterman(pair[0],pair[1],scoring_matrix,pen_gap_open,pen_gap_extend)\n",
    "            total_scores.append([output[2],pair])\n",
    "    #####determine true positives by TPR = 0.7\n",
    "    ###sort, largest to smallest\n",
    "    total_scores.sort(key=byFirst,reverse=True)\n",
    "    ####loop through and count TPR until matches TPR = 0.7\n",
    "    TP = 0\n",
    "    predicted_pos = []\n",
    "    predicted_neg = []\n",
    "    found_all_positives = False\n",
    "    for alignment in total_scores:\n",
    "        if found_all_positives == False:\n",
    "            predicted_pos.append(alignment)\n",
    "            if alignment[1] in true_pos: \n",
    "                TP += 1\n",
    "                TPR = float(TP)/float(len(true_pos))\n",
    "            if TPR == 0.7:\n",
    "                found_all_positives = True\n",
    "        else:\n",
    "            predicted_neg.append(alignment)   \n",
    "    ####prepare for plotting ROC curves\n",
    "    label = []\n",
    "    pred = []\n",
    "    ###by counting\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    ##\n",
    "    for alignment in predicted_pos:\n",
    "        pred.append(1)\n",
    "        if alignment[1] in true_pos:\n",
    "            label.append(1)\n",
    "            TP += 1\n",
    "        else:\n",
    "            label.append(0)\n",
    "            FP += 1\n",
    "    ##\n",
    "    for alignment in predicted_neg:\n",
    "        pred.append(0)\n",
    "        if alignment[1] in true_neg:\n",
    "            label.append(0)\n",
    "            TN += 1\n",
    "        else:\n",
    "            label.append(1)\n",
    "            FN += 1\n",
    "    #####plot\n",
    "    fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "    auc = metrics.roc_auc_score(label, pred)\n",
    "    ###\n",
    "    plt.plot(fpr,tpr,label=blosum_files[matrix_num]+\" auc=\"+str(auc),linewidth=line_widths[matrix_num%2],alpha=0.5)\n",
    "    #####save confusion matrix\n",
    "    confusion = [blosum_files[matrix_num],[TP,FP,TN,FN]]\n",
    "    total_confusions.append(confusion)\n",
    "    #####\n",
    "    matrix_num +=1\n",
    "########\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.legend(loc=0)\n",
    "plt.suptitle('Fig 7. ROC curve for MATIO blosum matrix before and after matrix optimization.')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Now let's look at the confusion matrices between the two alignment scoring matrices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for confusion in total_confusions:\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Q2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.4. Future improvements for optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### I have implemented a modified particle swarm algorithm. I wrote the particle swarm algorithm to handle BLOSUM matrices specifically with the following features:\n",
    "    Makes matrices symetrical\n",
    "    Calculates using my smith-waterman algorithm\n",
    "    Introduces a jitter for the scoring matrix at each iteration\n",
    "#### I chose this algorithm because:\n",
    "    It is applicable to any function\n",
    "    Intuitive design and implementation\n",
    "    low number of parameters to test (which I did on small scale).\n",
    "    Searches a global space quickly and is not easily caught in local minima.\n",
    "#### I implemented a small jitter for the scoring matrix because I observed in my testing that the particle with highest fitness often failed to reach a higher fitness level. After I implemented the jitter, oftentimes that particle reached an even higher level of jitter by randomizing the matrix by small quantities. Because the particle swarm memorizes (for each particle) its previous best position, I reasoned that if the jitter was detrimental, it would revert back to its previous best position.\n",
    "\n",
    "#### To improve this algorithm I would implement a \"reproducing\" particle swarm algorithm. At each iteration I would take the highest fitness particle, make copies of it with significant quantities of change in each copy, and then eliminate the lowest fitness particles. In this way I would combine the benefits of the particle swarm algorithm, specifically how it searches a global space quickly, but also combine the benefits of local optimization. By taking an optimized solution and then searching around that solution, I can search the global space first and then sample the local space once a candidate region with high fitness has been found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Q2.5 \n",
    "\n",
    "#### Necessary features for a global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#########determine true positives by FPR in {0.0,0.1,0.2,0.3}\n",
    "\n",
    "####\n",
    "total_confusions = []\n",
    "####\n",
    "pen_gap_extend = -5\n",
    "pen_gap_open = -6\n",
    "#####################\n",
    "#####loop through scoring matrices and calculate confusion for each one\n",
    "#####################\n",
    "for scoring_matrix in blosums:\n",
    "    total_scores = []\n",
    "    ########do alignments for all pairs\n",
    "    for file in all_pairs:\n",
    "        for pair in file:\n",
    "            ###this contains just the scores\n",
    "            output = smith_waterman.smith_waterman(pair[0],pair[1],scoring_matrix,pen_gap_open,pen_gap_extend)\n",
    "            total_scores.append([output[2],pair])\n",
    "    ##########\n",
    "    \n",
    "    ###sort, largest to smallest\n",
    "    total_scores.sort(key=byFirst,reverse=True)\n",
    "    ####loop through and count TPR until matches TPR = 0.7\n",
    "    TP = 0\n",
    "    predicted_pos = []\n",
    "    predicted_neg = []\n",
    "    found_all_positives = False\n",
    "    for alignment in total_scores:\n",
    "        if found_all_positives == False:\n",
    "            predicted_pos.append(alignment)\n",
    "            if alignment[1] in true_pos: \n",
    "                TP += 1\n",
    "                TPR = float(TP)/float(len(true_pos))\n",
    "            if TPR == 0.7:\n",
    "                found_all_positives = True\n",
    "        else:\n",
    "            predicted_neg.append(alignment)   \n",
    "    ####prepare for plotting ROC curves\n",
    "    label = []\n",
    "    pred = []\n",
    "    ###by counting\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    ##\n",
    "    for alignment in predicted_pos:\n",
    "        pred.append(1)\n",
    "        if alignment[1] in true_pos:\n",
    "            label.append(1)\n",
    "            TP += 1\n",
    "        else:\n",
    "            label.append(0)\n",
    "            FP += 1\n",
    "    ##\n",
    "    for alignment in predicted_neg:\n",
    "        pred.append(0)\n",
    "        if alignment[1] in true_neg:\n",
    "            label.append(0)\n",
    "            TN += 1\n",
    "        else:\n",
    "            label.append(1)\n",
    "            FN += 1\n",
    "    #####plot\n",
    "    fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
    "    auc = metrics.roc_auc_score(label, pred)\n",
    "    ###\n",
    "    fig = plt.plot(fpr,tpr,label=blosum_files[matrix_num]+\" auc=\"+str(auc),linewidth=line_widths[matrix_num%2],alpha=0.5)\n",
    "    #####save confusion matrix\n",
    "    confusion = [blosum_files[matrix_num],[TP,FP,TN,FN]]\n",
    "    total_confusions.append(confusion)\n",
    "\n",
    "########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
